\documentclass[a4paper, twocolumn, twoside]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[backend=biber]{biblatex}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{minted}
\usepackage{tikz}
\usepackage{listofitems}
\usepackage{amsmath}
\usepackage{tcolorbox}
\usepackage{etoolbox}
\usepackage[
	top=2cm, % Top margin
	bottom=2cm, % Bottom margin
	left=1.5cm, % Left margin
	right=1.5cm, % Right margin
	footskip=1cm, % Space from the bottom margin to the baseline of the footer
	headsep=0.75cm, % Space from the top margin to the baseline of the header
	columnsep=20pt, % Space between text columns (in twocolumn mode)
]{geometry}

\addbibresource{references.bib}

\BeforeBeginEnvironment{minted}{\begin{tcolorbox}}%
\AfterEndEnvironment{minted}{\end{tcolorbox}}%

\colorlet{myred}{red!80!black}
\colorlet{myblue}{blue!80!black}
\colorlet{mygreen}{green!60!black}
\colorlet{myorange}{orange!70!red!60!black}
\colorlet{mydarkred}{red!30!black}
\colorlet{mydarkblue}{blue!40!black}
\colorlet{mydarkgreen}{green!30!black}

\tikzset{
  >=latex, % for default LaTeX arrow head
  node/.style={thick,circle,draw=myblue,minimum size=22,inner sep=0.5,outer sep=0.6},
  node in/.style={node,green!20!black,draw=mygreen!30!black,fill=mygreen!25},
  node hidden/.style={node,blue!20!black,draw=myblue!30!black,fill=myblue!20},
  node convol/.style={node,orange!20!black,draw=myorange!30!black,fill=myorange!20},
  node out/.style={node,red!20!black,draw=myred!30!black,fill=myred!20},
  connect/.style={thick,mydarkblue}, %,line cap=round
  connect arrow/.style={-{Latex[length=4,width=3.5]},thick,mydarkblue,shorten <=0.5,shorten >=1},
  node 1/.style={node in}, % node styles, numbered for easy mapping with \nstyle
  node 2/.style={node hidden},
  node 3/.style={node out}
}
\def\nstyle{int(\lay<\Nnodlen?min(2,\lay):3)} % map layer number onto 1, 2, or 3

\tikzstyle{densenode}=[thick,draw=blue,fill=blue!20,circle,minimum size=22]
\tikzstyle{activationnode}=[thick,draw=red,fill=red!20,circle,minimum size=22]

\hypersetup{
    colorlinks,
    linkcolor={black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black},
	frenchlinks=true,
}

\title{Deep learning: Neural Network from scratch\\
\textit{creating a neural network library to solve the mnist dataset}}
\author{Adrien PELFRESNE - Alexis VAPAILLE}
\date{\today}


\begin{document}
	\onecolumn
    \maketitle
	\tableofcontents

	\twocolumn
	\section{Abstract}
	\textit{We have created a deep neural network "library" from scratch, in rust, without the use of any machine learning or deep learning library.\\
	The goal of this project was to solve the mnist dataset of handwritten digits, and to provide performances comparaison between
	two multi-layer-perceptron, with and without convolution.\\
	Our library let you create your own sequential neural network, with a simple and declarative api and is widely open to extension.
	This project also include a drawing mode, when you can draw your own digit and see what the model guess.
	}

	\section{Motivation}
	Our motivation with this \textit{from scratch} approach was to deepen our understanding of neural networks.
	Because high level library like \href{https://keras.io/}{keras} and the incredible level of abstraction that come with it,
	let us sometimes forgot the inner machinery. nevertheless,
	this underlying work that those library are doing is passionating, and we through it was a shame to be a simple user of those interface.
	The only (methematical) helper library that we have used is \href{https://crates.io/crates/ndarray}{ndarray}
	which provides an n-dimensional container for general elements and for numerics, and efficients matrix operations on the gpu.\\
	You can find our project on \href{https://github.com/dirdr/neural_network_from_scratch}{github}, we widely encourage reader to check the source code,
	as in this report, we won't go into code specific details and focus more on the abstract explanation.\\
	The project is split into : the actual neural network lib, the mnist exemple, which is using the library, as well a our report sources and the gui.

	\section{Sequential neural network}
	The multi-layer perceptron is known  as a \textit{Sequential} neural network, meaning that the \textbf{output}
	$Y_N$ of the layer $L_N$ is the \textbf{input} $X_{N+1}$ of the next layer $L_{N+1}$.\\
	$$
	Y_{N} = X_{N+1}
	$$
	and conversely
	$$
	X_{N} = Y_{N-1}
	$$
	with subscript $N$ indentifying layers in sequential order.
	from the input layer, when we pass our data, through the output layer, data flows through the network and through different kind of layers.

	\subsection{General layer interface}
	We have defined a general \textit{Layer} interface, to be implemented by all the differents layer we gonna use.\\
	This interface has two main method : \textbf{feed\_forward} and \textbf{propagate\_backward},
	The \textit{feed forward} method take the input vector $X$ as parameter and return the output vector $Y$ of the layer.
	and the \textit{propagate backward} method take as parameters the layer output gradient $\frac{\partial C}{\partial Y}$ and return the layer input gradient $\frac{\partial C}{\partial X}$.
	We will cover the use of these function later, alongside the theorical explanation of these concepts.

	\subsection{Dense layer}
	In a dense layer, also knowed as \textit{Linear layer} each input neuron is connected to every output neurone,
	each connexion is called a \textit{weight}, $w_{ij}$ is the weight connecting neurone $x_i$ (from the input) to neurone $y_j$ (to the output).

	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[x=2.2cm,y=1.5cm]
		  \readlist\Nnod{3,4} % number of nodes per layer
		  % \Nnodlen = length of \Nnod (i.e. total number of layers)
		  % \Nnod[1] = element (number of nodes) at index 1
		  \foreachitem \N \in \Nnod{ % loop over layers
			% \N     = current element in this iteration (i.e. number of nodes for this layer)
			% \Ncnt  = index of current layer in this iteration
			\foreach \i [evaluate={\x=\Ncnt; \y=\N/2-\i+0.5; \prev=int(\Ncnt-1);}] in {1,...,\N}{ % loop over nodes
			  \node[densenode] (N\Ncnt-\i) at (\x,\y) {};
			  \ifnum\Ncnt>1 % connect to previous layer
				\foreach \j in {1,...,\Nnod[\prev]}{ % loop over nodes in previous layer
				  \draw[thick] (N\prev-\j) -- (N\Ncnt-\i); % connect arrows directly
				}
			  \fi % else: nothing to connect first layer
			}
		  }
		\end{tikzpicture}
	\caption{a Dense Layer}
	\end{figure}
	
	The output value $y_j$ of a dense layer neuron is given by
	$$
	y_j = \sum_{i=1}^{n} x_i w_{i,j} + b_j
	$$
	
	with $b_j$ the bias term for the output neuron $j$.
	This calculation can be expressed using matrices operation on whole vectors.

	$$
	Y = XW + B
	$$

	\subsection{Activation layer}
	In a lot of deep neural network content, an activation function is applied inside the dense layer to produce the $y$ output value from the weighted sum $z$.
	We choose, in our implementation, to enhance the seperation of concerns, with a decoupled version.\\

	\begin{figure}[H]
	\centering
	\begin{tikzpicture}[x=2.2cm,y=1.5cm]
	  \readlist\Nnod{4,4} % Define two layers, each with 4 nodes
	  % Loop over both layers
	  \foreachitem \N \in \Nnod{
		\foreach \i [evaluate={\x=\Ncnt; \y=\N/2-\i+0.5; \prev=int(\Ncnt-1);}] in {1,...,\N}{
		  \node[activationnode] (N\Ncnt-\i) at (\x,\y) {};
		  % If not the first layer, connect nodes from the previous layer
		  \ifnum\Ncnt>1
			\draw[thick] (N\prev-\i) -- (N\Ncnt-\i); % Connect nodes element-wise
		  \fi
		}
	  }
	\end{tikzpicture}
	\caption{Element-wise Connections Between Two Layers}
	\end{figure}

	The Activation layer take a vector of size $n$ as input and produce a same length vector as a output, with the activation function applied 
	to each neuron.
	we must note that some activations function transform a vector by mapping individual component through the function, like the ReLU

	$$
	ReLU(z) = max(0, z)
	$$

	while other activation functions such as \textit{softmax} take vector  $z$ of $K$ real number,
	and is used to convert a vector of $K$ real number into a probability distribution of $K$ possible outcomes.

	$$
	\sigma : \mathbb{R}^{K} \rightarrow (0, 1)^K, K \geq 1
	$$

	is computed by taking a vector $z = (z_1, ..., z_k) \in \mathbb{R}^K$ and compute each component of a vector $\sigma(\mathbf{z}) \in (0, 1)^K$ 

	$$
	\sigma(\mathbf{z})_i = \frac{e^{z_i}}{\sum_{j = 1}^{K} e^{z_j}}
	$$

	we have implemented a variety of activations function, to try different options and see what works the best with the mnist dataset.

	\section{Cost function}
	To mesure how well our neural network perform, we use a cost function, which output a real number,
	by comparing the neural network \textit{output}, and the effective \textit{observed} value.
	A simple cost function is the meaned squared error, which is defined as : 

	$$
	\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2
	$$

	this cost function is great for regression neural network when we want to predict a continuous value, but for a classification task,
	like the mnist data set (when we need to classifie each image)
	we can use the cross entropy cost function, defined as :

	$$
		\text{Cross Entropy} = -\sum_{c=1}^{C} y_{c} \log(\hat{y}_{c})
	$$

	with $C$ the number of class (eg: 10 for the mnist dataset), $y_{c}$ the observed probability, and $\hat{y}_{c}$ the neural network output.

	and even
	$$
		\text{Cross Entropy} = -\log(\hat{y}_{c})
	$$

	if $y_{c}$ is a one hot encoded, vector of observed values, (ie: 1 for the observed class and 0 for others).

	\section{The learning process}
	\subsection{Gradient}
	The gradient of a function $\nabla f$ is the vector field that represents the direction
	and rate of the quickest increase of the function from a point $p$.
	We can visualize the gradient of the function $-(\cos^2 x  +\cos^2 y)^2$

	\begin{figure}
		\begin{center}
			\includegraphics[width=\columnwidth]{images/gradient_2d.png}
		\end{center}
		\caption{Function representation and gradient field of the function $-(\cos^2 x  +\cos^2 y)^2$}\label{fig:gradien2d}
	\end{figure}

	at the bottom of the image, we can visualize the vector field for each point $(x, y)$. with the arrow representing the quickest increase.
	
	\subsection{Minimization}
	To make our neural network lean, we want to adjust his parameters (ie: weights and biases) to \textbf{minimize the cost function $C$}.
	The algorithm used to minimize the cost function is known as the \textit{Gradient descent}, and the idea, is to get down our function by going through the stepest descent
	in the function, repeating that way we are sure to reach, at least a local minimum.

	Here is the process for a gradient descent step :
	\begin{enumerate}
		\item feed \textbf{all} your input data points into the network, calculating the cost for every output.
		\item calculate the averaged cost function.
		\item compute the gradient of the averaged cost function \textbf{with respect to the network parameters}.
		\item update the parameters in the opposite direction of the gradient
	\end{enumerate}

	\subsection{backpropagation}

	The algorithm used to calculate the gradient of the cost function with respect to the neural network parameters
	is called backpropagation. It is a way to precisely calculate
	(and not only estimate like the finite difference method) this gradient.\\
	The gradient will be calculated for each layer,
	starting from the last layer and going all the way back to the first layer.
	The key methematical tool used in backpropagation is the chain rule,
	which allow the gradient of the cost function
	to be split into gradient of simpler functions at each neuron within the network.\\
	For each layer, to calculate the parameters gradient $\frac{\partial C}{\partial P}$,
	we need to have the output gradient $\frac{\partial C}{\partial Y}$,
	this gradient will be given to us by the next layer. 

	we also want to calculate $\frac{\partial C}{\partial X}$, the input gradient $X$, to give it to the previous layer,
	which will use it as her own \textbf{output gradient}, because, as we said, the output gradient of one layer is the input gradient of the next layer

	\subsection{Dense layer backpropagation}

	The dense layer have two trainable parameters, the weigths, $W$ and the biases $B$.
	Starting with the gradient of the cost function with respect to the weights, we are given
	the output gradient :

	\begin{align}
		\frac{\partial C}{\partial Y} &= \begin{bmatrix}
		\frac{\partial C}{\partial y_1} \\
		\frac{\partial C}{\partial y_2} \\
        \vdots \\
	   \frac{\partial C}{\partial y_j} \\
	\end{bmatrix}
	\end{align}

	The cost function $C$ depend on $Y$ which depend on $W$ thus $C$ depend on $W$

	$$
    \frac{\partial C}{\partial W} = \frac{\partial C}{\partial Y} \frac{\partial Y}{\partial W}
	$$

	We calculate each weight gradient component $\frac{\partial C }{\partial W_{ij}}$

	$$
    \frac{\partial C}{\partial W_{ij}} = \sum_{l=1}^{N} \frac{\partial L}{\partial Y_{lj}} \frac{\partial Y_{lj}}{\partial W_{ij}}
	$$

	because $W_{ij}$ is used in every example for calculating the $j^{th}$ column of the output matrix. Let's look at the formula for $Y_{lj}$ to get the derivative

	$$
		Y_{lj} = X_{l1}W_{1j} + \cdots + X_{li}W_{ij} + \cdots + X_{lp}W_{pj} + b_{j}
	$$
	$$
		\frac{\partial Y_{lj}}{\partial W_{ij}} = X_{li}
	$$
	$$
		\implies \frac{\partial C}{\partial W_{ij}} = \sum_{l=1}^{N} \frac{\partial C}{\partial Y_{lj}} X_{li} = \sum_{l=1}^{N} X^{T}_{il}\frac{\partial C}{\partial Y_{lj}}
	$$

	So finally 

	$$
		\frac{\partial C}{\partial W} = X^{T} \frac{\partial C}{dY}
	$$

	for the biases $B$.

	\begin{align}
		\frac{\partial C}{\partial b} &= \frac{\partial C}{\partial Y} \frac{\partial Y}{\partial b}\\
		\frac{\partial C}{\partial b_{i}} &= \sum_{l=1}^{N} \frac{\partial C}{\partial Y_{li}} \frac{\partial Y_{li}}{db}
	\end{align}

	since the bias term $b_{i}$ is used in the evaluation of the entire column of $Y$.

	$$
		\frac{\partial Y_{li}}{\partial b_{i}} = 1
	$$
	$$
		\frac{\partial C}{db_{i}} = \sum_{l=1}^{N} \frac{\partial C}{\partial Y_{li}}
	$$
	$$
		\frac{\partial C}{\partial b} = \frac{\partial C}{\partial Y}
	$$

	and lastly, we calculate the gradient with respect to $X$

	\begin{align}
		\frac{\partial C}{\partial X} &= \frac{\partial C}{\partial Y} \frac{\partial Y}{\partial X}\\
		\frac{\partial C}{\partial X_{ij}} &= \sum_{l=1}^{k} \frac{\partial C}{\partial Y_{il}} \frac{\partial Y_{il}}{\partial X_{ij}}
	\end{align}

	since the data point $i$ will only influence the data point $i$ in $Y$. Other data points will not be affected. Further, $X_{ij}$ is used in calculation of every dimension of $Y_{i,:}$. To calculate the gradient,

	$$
		Y_{il} = \sum_{t=1}^{p} X_{it}W_{tl}
	$$
	$$
		\frac{\partial Y_{il}}{\partial X_{ij}} = W_{jl}
	$$
	$$
		\frac{\partial C}{\partial X_{ij}} = \sum_{l=1}^{k} \frac{\partial C}{\partial Y_{il}}W_{jl}
		= \sum_{l=1}^{k} \frac{\partial C}{\partial Y_{il}} W_{lj}^{T}
	$$
	$$
		\implies \frac{\partial C}{\partial X} = \frac{\partial C}{\partial Y} W^{T}
	$$

	\subsection{Activation layer backpropagation}

	An activation layer doesn't have any trainable parameters, so we just gonna focus on the input gradient calculation.

	we are given
	the output gradient $\frac{\partial C}{\partial Y}$:
	we know that 

	\begin{align*}
		Y &= \begin{bmatrix}
		f(X_1) \\
		f(X_2) \\
        \vdots \\
		f(X_i)
	\end{bmatrix}
	\end{align*}

	$$
    \frac{\partial C}{\partial X} = \frac{\partial C}{\partial Y} \frac{\partial Y}{\partial X}
	$$

	$$
    \frac{\partial C}{\partial X_{ij}} = \sum_{l=1}^{N} \frac{\partial C}{\partial Y_{lj}} \frac{\partial Y_{lj}}{\partial X_{ij}}
	$$

	using the same procedure as for the previous calculations

	$$
	\implies \frac{\partial C}{\partial X} = \frac{\partial C}{\partial Y} \odot Y\prime
	$$

	with 

	\begin{align*}
		Y\prime &= \begin{bmatrix}
		f\prime(X_1) \\
		f\prime(X_2) \\
        \vdots \\
		f\prime(X_i)
	\end{bmatrix}
	\end{align*}

	\section{Optimizers}
	
	At this point, to updates a neural network parameter $\theta$, we the gradient descent formula,
	with a fix learning rate $\eta$

	$$
	\theta := \theta - \eta \frac{\partial C}{\partial \theta}
	$$

	This is know, in the keras api for exemple as the \textit{Stochastic gradient descent optimizer},
	but it exist other optimizers such as \textit{Adam}.

	\subsection{Adam}
	Adam accelerate the convergence towards the optimal set of weights by taking into account pass gradient,
	and adam will adapt the learning rate for each individual weight.

	ADAM initializes two vectors, 
	$m$ and $v$, which store the exponential moving averages of past gradients and past squared gradients,
	respectively. These vectors are used to scale the gradient updates adaptatively.

	\begin{enumerate}
	  \item \textbf{Initialization:} Initialize two vectors, $m$ and $v$, to store the moving averages of the gradients and their squares, respectively.
	  \item \textbf{Computing Moving Averages of the Gradients:}
		\begin{align*}
		  m_t &= \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t, \\
		  v_t &= \beta_2 \cdot v_{t-1} + (1 - \beta_2) \cdot g_t^2,
		\end{align*}
		where $g_t$ is the gradient at time step $t$, and $\beta_1$ and $\beta_2$ are factors that control the decay rates.
	  \item \textbf{Bias Correction:} Correct initial bias in $m$ and $v$:
		\begin{align*}
		  \hat{m}_t &= \frac{m_t}{1 - \beta_1^t}, \\
		  \hat{v}_t &= \frac{v_t}{1 - \beta_2^t}.
		\end{align*}
	  \item \textbf{Update Weights:} Adjust weights based on the corrected moments:
		\begin{equation*}
		  \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \cdot \hat{m}_t,
		\end{equation*}
		where $\theta$ are the parameters, $\eta$ is the learning rate, and $\epsilon$ is a small constant for numerical stability.
	\end{enumerate}

	\section{All about batch}
	We went through several feed forward implementations. The first one was to pass data point one by one in the network
	$x \in \mathbb{R}^{i}$\dots. This was very slow, for exemple, for the mnist dataset, which has 60k training exemples,
	we where going through the whole neural network : feed forward, cost evaluation, back propagation, 60k times.
	But we then leraned that we can instead pass \textit{batch} of data in the neural network, in one time, and this batch can
	be of any length.
	the input then becomes $x \in M_{nxi} (\mathbb{R})$ with each line of the input matrice representing a single data point.

	The calculation became much faster, because we can now feed $n$ element at a time in the neural network.

	\section{Initializer}
	Initializers determine the starting weights of a neural network, it is important to choose the right initializer, depending
	on our netwrok architecture, to avoid problem like vanishing and exploding gradient, and to also optimizer convergence.

	At the moment we are writing this report, we have imoplemented two initializer inside our library,

	\begin{enumerate}
		\item{he}
	The He initializer, designed for ReLu activation functions,
	initializes weights from a normal distribution centered at zero with a standard deviation of 
	$\sqrt{\frac{2}{n}}$ (where $n$ is the number of input nodes).
	This setup helps prevent the vanishing gradient problem in deep networks with ReLu activations,
	ensuring that gradients remain large enough to sustain effective learning through many layers.
		\item{Glorot uniform}
	Conversely, the GlorotUniform initializer, 
	also known as Xavier Uniform, is ideal for networks using sigmoid or tanh activations.
	It selects weights from a uniform distribution within $[-c, c]$,
	where $c = \sqrt{\frac{6}{n_{\text{in}} + n_{\text{out}}}}$.
	This approach maintains a balance in the variance of neurons' outputs across the network,
	aiding in stable gradient flow in deep networks with saturating activations.
	\end{enumerate}

	\section{Convolutional neural network}
	ALEXIS a toi de travailler

	\section{Metrics}
	With the mnist datset, which is a classification problem, we can implements multiple metrics
	to evaluate the network performances, we will explain the one we implemented in our library.

	\begin{enumerate}
		\item Accuracy measures the proportion of correct prediction to the total observations in the dataset.
		for exemple if we have correctly classified 950 image out of 1000, the accuracy will be 95percent.
		$$
		\text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}}
		$$

		Precision and Recall are two metrics acting on a specified class.
		\textbf{Retrieved elements} are all the network prediction for a specific class.
		\textbf{Relevant elements} are all the correct instances of 
		the class \cite{wiki_precision_recall}.

		\item Precision answer the question : \textit{How many retrieved items are relevant}
		$$
		\text{Precision} = \frac{\text{Relevant retreived instance}}{\text{All retrieved instance}}
		$$
		\item Recall answers the question: \textit{How many relevant item are retrieved}
		$$
		\text{Recall} = \frac{\text{Relevant instances}}{\text{All relevants instance}}
		$$
	\end{enumerate}

	\section{Training, Validation, and Test Sets}
	To monitor the performances of a neural network effectively,
	it is important to break down the dataset into three distinct subsets:
	training, validation, and test sets.

	\begin{itemize}
\item{\textbf{Training set}} : The training set is used during the leraning phase,
	with training data directly influencing the parameters updates
\item{\textbf{Validation set}} : The validation set is used to provide an unbiased evaluation of a model fit
	on the training dataset while tuning the model's hyperparameters.
	This set is used during training, to prevent overfitting when the model performs well on the training data
	but poorly on unseen data.
\item{\textbf{Test set}} :	The test set is used only after the model's training and validation phases are complete.
	It provides the final, unbiased performance metric of the neural network.
	\end{itemize}

	\section{Results}
	We include a small code snippet, showing our custom library api to declare a sequential neural network.

	\begin{minted}[breaklines, tabsize=2]{rust}
let net = NeuralNetworkBuilder::new()
	.push(DenseLayer::new(
		28 * 28,
		32,
		InitializerType::He,
	))
	.push(
		ActivationLayer::from(Activation::ReLU)
	)
	.push(
		DenseLayer::new(32, 10, InitializerType::He)
	)
	.push(
		ActivationLayer::from(
			Activation::Softmax
		)
	);
	.watch(MetricsType::Accuracy)
	.watch(MetricsType::Precision)
	.watch(MetricsType::Recall)
Ok(net.compile(GradientDescent::new(0.01), CostFunction::CrossEntropy)?)
	\end{minted}

	the layer are added in sequential order with the push method, we watched Accuracy, Precision and Recall.
	the \textit{watch} method will add a \textit{MetricsType} to the list of metrics that the program need to calculate.
	those metrics can be given over epochs for the training and validation dataset. and for the test dataset.

	To create a great network, we will try to reach the \textit{VC trade-off principle} \cite{LeCun2019} \cite{vapnik1974theory},
	this principle state that:

	\begin{enumerate}
		\item A more complex model might fit the training data very well (low training error)
			but risks overfitting, meaning it could perform poorly on new data
			because it is too tailored to the training set (high variance).
		\item A less complex model might not fit the training data as closely 
			(higher training error) but can generalize better on new data because 
			it does not capture the noise and specific details of the training set (low variance).
	\end{enumerate}

	Our challenge will thus be, to find the right level of complexity that minimizes both the error on the training data.

	\subsection{Multi-layer perceptron}
	before trying to get a great fitting model, we will anlyse the result of an overfitting model, to see 
	how this behavior translate into metrics. To make a model overfit, we have multiple options

	\begin{itemize}
		\item increase the model complexity (number of hidden layers, number of neuron per layer)
		\item reduce the batch size to make the learning process very granular 
			and increase the chance of the network leraning to much specific patterns
	\end{itemize}

	In our case we have choosen to lower the batch size, here is our network hyperparameters

	\begin{table}[H]
	\centering
	\begin{tabular}{|l|c|c|}
	\hline
	hyperparameters & epochs & batch size  \\
	\hline
	Value & 30 & 5   \\
	\hline
	\end{tabular}
	\caption{hyperparameters overfitting model}
	\end{table}

	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=\columnwidth]{images/cost_overfit.png}
		\end{center}
		\caption{Training vs Validation cost overfitting model}\label{fig:cost_overfit}
	\end{figure}

	In the cost comparaison between our training data and our validation data, the overfitting
	clearly stand out, our train cost (or loss) get very low, while the validation cost remain stable
	this mean that our neural network has learn to much specific pattern in the training data,
	making the error going very low on this set, but on the validation set, the network
	doesn't achieve a great generalization.

	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=\columnwidth]{images/accuracy_overfit.png}
		\end{center}
		\caption{Training vs Validation cost overfitting model}\label{fig:accuracy_overfit}
	\end{figure}

	The same observation applies to the evolution of accuracy over epochs.
	the accuracy reach a stunning 100percent on our training data, meaning that with
	the point used to train the network, it dont make any mistakes,
	but the validation accuracy struggle to get up.\\

	We have achieved our best accuracy with the following hyperparameters and network definition.

	\begin{table}[H]
	\centering
	\begin{tabular}{|l|c|c|}
	\hline
	hyperparameters & epochs & batch size  \\
	\hline
	Value & 15 & 100   \\
	\hline
	\end{tabular}
	\caption{hyperparameters greatfitting model}
	\end{table}


	\begin{minted}[breaklines, tabsize=2]{rust}
let net = SequentialBuilder::new()
	.push(
		DenseLayer::new(784, 256,
		InitializerType::He))
	.push(
		ActivationLayer::from(
			Activation::ReLU)
		)
	.push(
		DenseLayer::new(256, 256,
		InitializerType::He))
	.push(
		ActivationLayer::from(
			Activation::ReLU)
		)
	.push(
		DenseLayer::new(256, 10,
		InitializerType::GlorotUniform))
	.push(
		ActivationLayer::from
		(
			Activation::Softmax)
		)
	.watch(MetricsType::Accuracy);
Ok(net.compile(GradientDescent::new(0.04), CostFunction::CrossEntropy)?)
	\end{minted}


	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=\columnwidth]{images/cost_greatfit.png}
		\end{center}
		\caption{Training vs Validation cost greatfitting model}\label{fig:cost_greatfit}
	\end{figure}

	Here, our model seems to have generalized patterns, because the training cost and 
	the validation cost follow the same path, slowly increasing, with the gap between curves never blowing off the roof.

	we reach a validation cost of 0.097, the cost for the testing data set is 0.091.

	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=\columnwidth]{images/accuracy_greatfit.png}
		\end{center}
		\caption{Training vs Validation cost greatfitting model}\label{fig:accuracy_greatfit}
	\end{figure}

	we reach a validation accuracy of 97.10percent for the final eppochs, the accuracy for the testing data set is 97.31percent.
	which is not a \textit{state of the art} accuracy but is a good result.

	\subsection{Convolutional multi-layer perceptron}

	\section{Conclusion}
	This project of creating our own \textit{from scratch} library has brought us a lot of knowledge,
	It as made us greatly understand the whole neural network process.
	We have planned to add more functionality to our library and to optimize the code base even after the end of this project.
	we want to add more optimizers, the dropout layer, and a learning rate scheduler.
	and over the longer term, we'd like to add other neural network paradigm, such as Recurrent neural network.

	\nocite{*}
	\printbibliography

\end{document}
