@book{LeCun2019,
    title = {Quand la machine apprend: La r{\'e}volution des neurones
             artificiels et de l'apprentissage profond},
    author = {LeCun, Yann},
    year = {2019},
    publisher = {Odile Jacob},
}

@article{vapnik1974theory,
    title = {Theory of pattern recognition},
    author = {Vapnik, Vladimir and Chervonenkis, Alexey},
    year = {1974},
    publisher = {Nauka, Moscow},
}
@misc{wiki_precision_recall,
    author = {Wikipedia contributors},
    title = {Precision and recall --- {Wikipedia}{,} The Free Encyclopedia},
    year = {2024},
    url = {https://en.wikipedia.org/wiki/Precision_and_recall},
    note = {[Online; accessed 28-May-2024]},
}

@online{he_initialization,
    author = {Papers with Code},
    title = {He Initialization},
    url = {https://paperswithcode.com/method/he-initialization},
    year = {n.d.},
}

@online{cross_entropy_loss_guide,
    author = {V7 Labs},
    title = {A Guide to Cross-Entropy Loss},
    url = {https://www.v7labs.com/blog/cross-entropy-loss-guide},
    year = {n.d.},
}

@online{hadamard_product,
    author = {Wikipedia},
    title = {Hadamard product (matrices)},
    url = {https://en.wikipedia.org/wiki/Hadamard_product_(matrices)},
    year = {2024},
}

@online{backpropagation_softmax_cross_entropy,
    author = {Stack Exchange},
    title = {Backpropagation with Softmax Cross Entropy},
    url = {
           https://stats.stackexchange.com/questions/235528/backpropagation-with-softmax-cross-entropy
           },
    year = {2016},
}

@online{softmax_function,
    author = {Wikipedia},
    title = {Softmax function},
    url = {https://en.wikipedia.org/wiki/Softmax_function},
    year = {2024},
}

@online{matrice_jacobienne,
    author = {Wikip√©dia},
    title = {Matrice Jacobienne},
    url = {https://fr.wikipedia.org/wiki/Matrice_jacobienne},
    year = {2024},
}

@online{one_hot,
    author = {Wikipedia},
    title = {One-hot},
    url = {https://en.wikipedia.org/wiki/One-hot},
    year = {2024},
}

@online{cross_entropy_search,
    author = {Google},
    title = {Cross Entropy},
    url = {
           https://www.google.com/search?q=cross+entropy&sourceid=chrome&ie=UTF-8
           },
    year = {2024},
}

@online{derivative_softmax_cross_entropy,
    author = {Towards Data Science},
    title = {Derivative of the Softmax Function and the Categorical Cross
             Entropy Loss},
    url = {
           https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1
           },
    year = {2019},
}

@online{precision_and_recall,
    author = {Wikipedia},
    title = {Precision and recall},
    url = {https://en.wikipedia.org/wiki/Precision_and_recall},
    year = {2024},
}

@misc{kingma2017adam,
    title = {Adam: A Method for Stochastic Optimization},
    author = {Diederik P. Kingma and Jimmy Ba},
    year = {2017},
    eprint = {1412.6980},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
}
